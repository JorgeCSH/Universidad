{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "jrDx2BOWzFXU",
    "Fa8xtgGyzQPi",
    "BwHEkcUjzfbS"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "-------------------\n",
    "# Tarea Numerica N°2, Calculo en Varias Variables  (MA-2001)\n",
    "-------------------\n",
    "> Integrantes:\n",
    "    $\\rightarrow$ Jorge Cummins;  RUT: 21.353.175-1\n",
    "Seccion: 5\n",
    "Profesor de Catedra: Claudio Muñoz.\n",
    "Fecha de Entrega: 28 de Mayo de 2023\n"
   ],
   "metadata": {
    "id": "ZIsH_HPjvhdS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ## Sobre el Documento"
   ],
   "metadata": {
    "id": "2Ua7LZykxSuR"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### Indice:\n",
    ">   1.  ...................................................... (Parte 1.) Descripcion Teorica\n",
    ">   2.  ...................................................... (Parte 2.) \"Numerico\" [(a) y (b)]\n",
    ">   3.  ...................................................... Palabras Finales\n",
    ">\n",
    "> ### Componentes:\n",
    "> El presente documento es el solicitado en formato \"*jupyter Notebook*\" de la tarea numerica solicitada. En esta se encontraran cuadros de codigo, algunas anotaciones, cuadros de texto explicativos además de algunos ejemplos si la situacion lo amerita. Esto con el fin de servir como argumentacion o solucion directa a la evaluacion.\n",
    "\n",
    "> Los cuadros de texto corresponeran a la información sobre el codigo que le prosigue siguiendo un formato de \"*texto arriba, codigo abajo*\", el cual intentara cumplir el objetivo de explicar el funcionamiento del codigo en el presente. Pese a esto también existiran anotaciones extras en formato \"# *Anotaciones*\" color \"verde\" en el/los codigos que deberia tener un formato similar al siguiente:\n",
    "```\n",
    "1 # Anotacion\n",
    "2 Este es un codigo:              # Anotacion\n",
    "3     sirve para ejemplificar     # Anotacion\n",
    "4     el formato que se dijo      # Anotacion \n",
    "5                                 #\n",
    "6 previamente                     # Anotacion\n",
    "```\n",
    "> Estos seran parte del codigo pero no tendran funcion ninguna más que ser anotaciones insertadas por los desarrolladores para uso personal, aunque de ser necesario puede utilizarse como información sobre el documento/codigo.\n",
    "> ### Orden:\n",
    "> El documento estara estructurado mediante diferentes partes que se enumeran en el \"Indice\", en la primera parte (Parte 1.) y la segunda (Parte 2.) se encuentran las soluciones respectivas, mientra que en \"Palabras Finales\", comentarios respectivos a la realizacion del documeno o tarea.\n",
    "\n",
    "> Es importante informar que de ser necesario, se utilizaran codigos compartidos con el fin de mantener el orden y optimizar el proceso, el cual será denotado por una anotacion al inicio del cuadro de codigo de forma \"codigo compartido\". Para poder utilizar el codigo donde esté siendo reutilizado, será necesario inicializar el original. Un caso será la siguiente línea de codigos que permitira el acceso a librerias que podrian ser utilizadas.\n"
   ],
   "metadata": {
    "id": "9GiLnnngJaEl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ## Parte 1. Descripcion Teorica"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Dado a las caracteristicas de la entrega, en la cual ademas del documento prescente, se entrego un informe en formato PDF donde se contendran las soluciones respectivas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ## Parte 2. \"Numerico\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> La parte 2 de la tarea solicitada, se baso en dos diferentes estudios (aunque relacionados en la tematica presente) a programar. Esto se dividion en dos etapas para realizar la respectiva funcion.\n",
    "> Sin embargo, estas dos etapas llegaron a tener documentos o funcionalidades en comun, para lo cual se agregaron los siguientes codigos y celdas de codigos para optimizar el orden y proceso con estas funciones."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ========================================================================================================\n",
    "######################################### Librerias Importadas ###########################################\n",
    "# Codigo compartido --> Librerias export importadas\n",
    "import numpy as np\n",
    "######################################### Librerias Importadas ###########################################\n",
    "# ========================================================================================================"
   ],
   "metadata": {
    "id": "ud8Ehlcbzv3D"
   },
   "execution_count": 140,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "# ========================================================================================================\n",
    "########################################## Valores Utilizados ############################################\n",
    "# Codigo compartido --> Valores utilizados de manera general\n",
    "# Vector aleatorio (w1,w2,b) perteneciente a R3\n",
    "croissant = np.random.uniform(size=(3,1),low=0,high=1)               # Vector\n",
    "w1 = float(croissant[0])                                             # Componente w1\n",
    "w2 = float(croissant[1])                                             # Componente w2\n",
    "b = float(croissant[2])                                              # Commponente \"b\" o \"bias\"\n",
    "\n",
    "\n",
    "# Lista de vectores o instancias.\n",
    "d = [[9.0,7.0,0.0],[2.0,5.0,1.0],[3.2,4.94,1.0],[9.1,7.46,0.0],[1.6,4.83,1.0],[8.4,7.46,0.0],[8.0,7.28,0.0],[3.1,4.58,1.0],[6.3,9.14,0.0], [3.4,5.36,1.0]]\n",
    "# Vector o matriz de instancias (igual que el anterior pero de forma matricial)\n",
    "D = np.array(d)\n",
    "\n",
    "\n",
    "# Vector o punto de realizacion\n",
    "x0 = [[8,7]]                                                         # Forma de lista\n",
    "X0 = np.array(x0)                                                    # Forma vector\n",
    "\n",
    "\n",
    "# Condiciones iniciales/constantes\n",
    "k = 1000                                                            # Cantidad de iteraciones\n",
    "l = 0.01                                                            # Learning rate de la red neuronal\n",
    "########################################## Valores Utilizados ############################################\n",
    "# ========================================================================================================"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### (a) Programar algoritmo que \"Entrenara\" redes neuronales\n",
    "> Durante la etapa \"$a)$\", se solicito la realizacion del algoritmo llamado \"gradiente conjugado\" para los diferentes \"$k$\" dado a $k = 1,...,M$.\n",
    "> El algoritmo tiene la principal funcion de realizar la siguiente iteracion:\n",
    ">\\begin{align*} w_{1}^{k+1} &= w_{1}^{k}-l\\frac{\\partial C}{\\partial w_{1}} (w_{1}^{k}, w_{2}^{k}, b^{k}) \\\\ w_{2}^{k+1} &= w_{2}^{k}-l\\frac{\\partial C}{\\partial w_{2}} (w_{1}^{k}, w_{2}^{k}, b^{k}) \\\\ b^{k+1} &= b^{k}-l\\frac{\\partial C}{\\partial b} (w_{1}^{k}, w_{2}^{k}, b^{k}) \\end{align*}\n",
    "> Con $(w_{1}^{0}, w_{2}^{0}, b^{0}) \\in \\mathbb{R}^{3}$ como inicio, dados y aleatorios.\n",
    "> Para la realizacion, fue de gran importancia notar los parametros influyentes en nuestro problema, es decir, las funciones y valores presentes. En este caso, nos encontramos con las siguientes funciones:\n",
    " \\begin{enumerate}1.& \\text{Realizacion} \\\\ 2.& \\text{Funcion de costos} \\\\ 3.& \\text{Derivadas parciales funcion costos} \\end{enumerate}\n",
    "> En base a que la realizacion depende de las derivadas parciales, funcion de costos y finalmente, realizacion, se realizaron las siguientes funciones para realizar este proceso."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> #### 1. Realizacion\n",
    "> La primera situacion seria programar la realizacion de la red neuronal. En base a la informacion obtenidas en la parte 1, se realizaron los siguientes codigos:\n",
    "  El primero se encargaria de la realizacion de la funcion de activacion, en la cual se programaria la funcionn \"sigmoide\" y su derivada. la funcion que en este caso realizaria tal operacion se trataria de \"sigmoid\", la cual recibe como parametros a $s \\in \\mathbb{R}$ y el extra de \"tipo\", en cual si se elige \"$0$\", entregaria la funcion evaluada y, si se   elige \"$1$\", entregaria la derivada evaluada en el punto \"$s$\". las cuales en el ambito teorico se encuentran de la forma:\n",
    "  \\begin{align*} \\sigma(s) &=\\frac{e^s}{1+e^s} \\\\\\sigma'(s) &= \\frac{e^s}{(1+e^s)^2} \\end{align*}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "# ======================================== Tarea 2, Parte 2.a ============================================\n",
    "######################################### Funcion de Activacion ##########################################\n",
    "# Toma dos numeros y devuelve la funcion sigmoid o su derivada\n",
    "#           => 0, devuelve la funcion\n",
    "#           => 1, devuelve la derivada en torno a s\n",
    "def sigmoid(s, tipo):\n",
    "    e = np.exp(s)                                               # Evalua la exponencial en el punto \"s\"\n",
    "    denominador = (1+e)                                         # Denominador de la funcion\n",
    "    if tipo == 0:                                               # Condicional para evaluar funcion\n",
    "        sigmoide = (e)/(denominador)\n",
    "        return sigmoide\n",
    "    elif tipo == 1:                                             # Condicional para evaluar derivada\n",
    "        sigmoide = (e)/((denominador)**2)\n",
    "        return sigmoide\n",
    "######################################### Funcion de Activacion ##########################################\n",
    "# ======================================== Tarea 2, Parte 2.a ============================================"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Segundo, en base a la informacion calculada durante la parte 1, se programaria la realizacion de esta        ultima red \"$\\mathcal{R}(\\Phi)$\" evaluada en un punto $x_{0} \\in \\mathbb{R}^2$, es decir, \"$\\mathcal{R}(\\Phi)   (x_{0})$\".\n",
    ">\n",
    "> La funcion programada recibiria los parametros \"phi\" (representando a la realizacion), \"x\" (vector evaluado) y finalmente, \"tipo\" (Si se quiere evaluar la funcion o la realizacion de la funcion en un punto especifico) . Estas ultimas siguen las formas calculadas durante la primera parte de la tarea, las cuales quedan de la siguiente forma:\n",
    ">\\begin{align*} \\mathcal{R}(\\Phi)(x_{0}) &= \\sigma ({w_{1}x_{0,1}+w_{2}x_{0,2}+b}) \\end{align*}\n",
    ">\n",
    "> Ademas, dado a la utilidad que presentaria en el desarrollo, se programo una derivada \"general\", es decir, sin aplicarse las propiedades respectivas de estas con el fin de permitir adaptarlas dependiendo del contexto. Esta ultima quedaria de la forma:\n",
    ">\\begin{align*} \\mathcal{R}(\\Phi)(x_{0}) &= \\sigma' ({w_{1}x_{0,1}+w_{2}x_{0,2}+b}) \\end{align*}\n",
    ">\n",
    "> La cual se podria acceder dependiendo del parametro \"dif\", en la cual si se inserta \"$0$\" entregaria la realizacion evaluada en el punto \"$x_{0}$\" y \"$1$\", si se requiere la funcion sigma derivada.\n",
    ">\n",
    "> Despues de explicado lo realizado, el codigo quedaria como sigue."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "# ======================================== Tarea 2, Parte 2.a ============================================\n",
    "########################################## Realizacion ###################################################\n",
    "# Entrega la red neuronal realizada.\n",
    "# phi contiene los pesos y a la componente bias.\n",
    "# x es el vector input.\n",
    "# tipo es que se quiere calcular\n",
    "#           => 0 = valor sin evaluar \"x\"\n",
    "#           => 1 = valor tras evaluar \"sigma(x)\"\n",
    "def realizacion(phi,x,tipo,dif):\n",
    "    pesos = np.array([[float(phi[0]),float(phi[1])]])     # Se obtiene un vector con pesos (w1 y w2)\n",
    "    b = phi[2]                                            # Se obtiene el \"bias\" (b) de la realizacion\n",
    "    valoresTeorico = np.dot(pesos,np.transpose(x))        # |-  Suma entre componentes 1 y 2 ponderadas.\n",
    "    valoresNumerico = float(valoresTeorico)               # |   su obtencion se basa en producto punto de\n",
    "    operando = valoresNumerico+float(b)                   # |-  vectores\n",
    "    if tipo == 0:                                         # Condicional para evaluar funcion\n",
    "        evalu = sigmoid(operando,dif)\n",
    "        return evalu\n",
    "    elif tipo == 1:                                       # Condicional para evaluar derivada\n",
    "        evalu = sigmoid(operando,dif)\n",
    "        return evalu\n",
    "########################################## Realizacion ###################################################\n",
    "# ======================================== Tarea 2, Parte 2.a ============================================"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> #### 2. Funcion de costos\n",
    "> La funcion de costos constaria de una serie de operaciones que permitirian tanto obtener este parametro como realizar operaciones con esta.\n",
    "> Para el primer caso tendriamos que definir una forma de obtener los componentes que conforman a esta funcion, es deci:\n",
    "> \\begin{equation*} C_{i} = (\\mathcal{R}(\\Phi)(\\hat{x}_{0}^{i})-\\hat{x}_{f}^{i})\\end{equation*}\n",
    "> Donde el componente \"$i$\" no corresponde a una potencia, ni tampoco a una unidad imaginara, mas bien a la componente $i$-esima de la operacion de costos con $i=\\left\\{1...N\\right\\}$.\n",
    "> Esta operacion se obtendria aplicando las siguientes operaciones en base al codigo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "# ======================================== Tarea 2, Parte 2.a ============================================\n",
    "########################################## transformador #################################################\n",
    "# Componentes Funcion de Costos\n",
    "# Se llamo transformados porque opera cada valor dentro de la funcion de costos con el fin de realizar la\n",
    "# sumatoria.\n",
    "# Permite tambien realizar operaciones externas siempre y cuando sean en base a la funcion de costos.\n",
    "# Recibe phi, datos, el N cantidad de datos y los tipos1 y 2\n",
    "#           |=> si tipo1 = 0, realiza operacion normal\n",
    "#           |=> si tipo1 = 1, realiza diferencial\n",
    "#                        ||=> si tipo2 = 0, opera con w1\n",
    "#                        ||=> si tipo2 = 1, opera con w2\n",
    "#                        ||=> si tipo2 = 2, opera con b\n",
    "def transformador(phi, datos, tipo1, tipo2, N):\n",
    "    if tipo1 == 0:                                                               # Operacion comun\n",
    "        for i in range(N):\n",
    "            pdato = [] + [(realizacion(phi, np.transpose(np.array(datos[i][0:2])), tipo=1, dif=0) - datos[i][2:3]) ** 2]\n",
    "            ndato = pdato\n",
    "            return ndato\n",
    "    elif tipo1 == 1:                                                             # Operacion diferencial\n",
    "        if tipo2 == 0:                                                           # Derivado en torno a w1\n",
    "            for i in range(N):\n",
    "                pdato = [] + [(realizacion(phi, np.transpose(np.array(datos[i][0:2])), tipo=1, dif=1) - datos[i][2:3])*datos[i][0]]\n",
    "                ndato = pdato\n",
    "                return ndato\n",
    "        elif tipo2 == 1:                                                         # Derivado en torno a w2\n",
    "            for i in range(N):\n",
    "                pdato = [] + [(realizacion(phi, np.transpose(np.array(datos[i][0:2])), tipo=1, dif=1) - datos[i][2:3])*datos[i][1]]\n",
    "                ndato = pdato\n",
    "                return ndato\n",
    "        elif tipo2 == 2:                                                         # Derivado en torno a b\n",
    "            for i in range(N):\n",
    "                pdato = [] + [(realizacion(phi, np.transpose(np.array(datos[i][0:2])), tipo=1, dif=1) - datos[i][2:3])]\n",
    "                ndato = pdato\n",
    "                return ndato\n",
    "########################################## transformador #################################################\n",
    "# ======================================== Tarea 2, Parte 2.a ============================================"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> #### 3. Derivadas Parciales Funcion de Costos\n",
    "> Realizada las transformaciones para las componentes, la cual calcula el valor para cada una de los valores de la sumatoria en los diferentes casos presentes, se realizo la funcion de costos.\n",
    ">\n",
    "> Para el caso de esta nueva funcion, se tomaron las mismas iniciativas previas de separar en diferentes casos la funcion. Para lo cual se agrego un parametro extra como \"tipo 1\" para decidir el tipo de operacion entre calculo o evaluacion de derivada, y \"tipo 2\" para decidir en torno a que variable se iba a derivar esta funcion. Finalmente, la funcion quedo como."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "# ======================================== Tarea 2, Parte 2.a ============================================\n",
    "######################################## Funcion de Costos ###############################################\n",
    "# Recibe phi, datos y los tipos de operaciones\n",
    "#          |=> si tipo1 = 0, calcula el coste de esta\n",
    "#          |=> si tipo1 = 1, comienza a derivar\n",
    "#                 ||=> si tipo2 = 0, deriva en w1\n",
    "#                 ||=> si tipo2 = 1, deriva en w2\n",
    "#                 ||=> si tipo2 = 2, deriva en b\n",
    "def costo(phi, tipo1, tipo2, datos):\n",
    "    N = len(datos)\n",
    "    original = transformador(phi, datos, tipo1, tipo2, N)\n",
    "    dC = np.transpose(np.array(original))\n",
    "    if tipo1 == 0:                                       # Obtiene los costos evaluados de la realizacion\n",
    "        sumCosto = sum(original)\n",
    "        costoRealizacion = sumCosto/2\n",
    "        return costoRealizacion\n",
    "    elif tipo1 == 1:                                     # Obtiene las derivadas de los costos evaluados\n",
    "        if tipo2 == 0:                                                  # Derivada parcial en torno a w1\n",
    "            dw1 = transformador(phi, datos, 1, 0, N)\n",
    "            dw11 = np.array(dw1)\n",
    "            costoRealizacion = np.dot(dC, dw11)\n",
    "            return costoRealizacion\n",
    "        elif tipo2 == 1:                                                # Derivada parcial en torno a w2\n",
    "            dw2 = transformador(phi, datos, 1, 1, N)\n",
    "            dw22 = np.array(dw2)\n",
    "            costoRealizacion = np.dot(dC, dw22)\n",
    "            return costoRealizacion\n",
    "        elif tipo2 == 2:                                                # Derivada parcial en torno a b\n",
    "            db = transformador(phi, datos, 1, 2, N)\n",
    "            dbb = np.array(db)\n",
    "            costoRealizacion = np.dot(dC, dbb)\n",
    "            return costoRealizacion\n",
    "######################################## Funcion de Costos ###############################################\n",
    "# ======================================== Tarea 2, Parte 2.a ============================================"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Considerando las derivadas parciales, se utilizaron los codigos previamente explicados para realizar el algoritmo que finalmente entrenaria la red neuronal.\n",
    ">\n",
    "> La realizacion se basa en el gradiente conjugado, la cual es un metodo de buscar los puntos criticos y asi disminuir o minimizar el error de la realizacion.\n",
    ">\n",
    "> Siendo que el gradiente de la funcion estaria dado por:\n",
    ">\\begin{equation*} \\nabla C(w_{1}, w_{2}, b) &= \\begin{pmatrix}\\frac{\\partial C}{\\partial w_{1}} \\\\ \\frac{\\partial C}{\\partial w_{2}}\\\\\\frac{\\partial C}{\\partial b} \\end{pmatrix}^{T} \\end{equation*}\n",
    ">\n",
    "> Ademas del algoritmo solicitado y las funciones planteadas, quedarian las siguientes operaciones"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "# ======================================== Tarea 2, Parte 2.a ============================================\n",
    "####################################### Gradiente Conjugado ##############################################\n",
    "# Itera con el fin de encontrar un Phi que se parezca al de realizar una red neuronal iterada\n",
    "# recibe k, o cantidad de iteraciones\n",
    "# w1, w2, b, valores de un phi aleatorio\n",
    "# Recibe datos de la realizacion\n",
    "def gradienteConjugado(k, w1, w2, b, l, datos):\n",
    "    w01 = w1                                                        # -|\n",
    "    w02 = w2                                                        #  |--> |Definir variables iniciales\n",
    "    b0 = b                                                          # -|\n",
    "    phix = np.array([[w01], [w02], [b0]])                           # Vector solucion inicial\n",
    "    if  k == 0:                                                     #\n",
    "        return phix                                                 # Fin de iterador\n",
    "    else:                                                           #\n",
    "        nw1 = float(phix[0])-(l)*(costo(phix, 1, 0, datos))         # -|\n",
    "        nw2 = float(phix[1])-(l)*(costo(phix, 1, 0, datos))         #  |--> |Obtener nuevas variables\n",
    "        nb0 = float(phix[2])-(l)*(costo(phix, 1, 0, datos))         # -|\n",
    "        w1 = float(nw1)                                             # -|\n",
    "        w2 = float(nw2)                                             #  |--> |Definir nuevas variables\n",
    "        b = float(nb0)                                              # -|\n",
    "        return gradienteConjugado(k-1, w1, w2, b, l, datos)         #\n",
    "####################################### Gradiente Conjugado ##############################################\n",
    "# ======================================== Tarea 2, Parte 2.a ============================================"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Con lo cual tendriamos el algoritmo que permite realizar el gradiente conjugado en base a las funciones planteadas. Si bien inicialmente puede ser un orden disperso entre operaciones, se ideo esta funcion con el fin de tener operaciones internas que realizen las respectivas evaluaciones de valores correspondientes. Ademas de otorgar variaciones en los resultados que estos arrojarian, esto en el sentido de si se trataria del valor evaluado de alguna funcion o la derivada (tanto total como parcial) de la funcion en el caso de que pudiera llegar a ser necesario."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ### (b) Realizar M = 1000 iteraciones del algoritmo con el fin de entrentar la red $\\Phi$. Ademas, encontrar el valor de la realizacion en el punto $(8, 7)$\n",
    "> Dado $D$ con 10 instancias consistentes de dos valores input y un tercero de output en {$0,1$} de la siguiente manera:\n",
    "> $D=${{$9, 7.0, 0$}, {$2, 5.0, 1$}, {$3.2, 4.94, 1$}, {$9.1, 7.46, 0$}, {$1.6, 4.83, 1$}, {$8.4, 7.46, 0$}, {$8, 7.28, 0$}, {$3.1, 4.58, 1$}, {$6.3, 9.14, 0$}, {$3.4, 5.36, 1$}}\n",
    "> Realizar M=1000 iteraciones del gradiente conjugado (anterior) para lograr el objetivo.\n",
    ">\n",
    "> Dado a las funciones realizadas en la parte a), se desarrollo un cuadro de codigo que permitiera entrenar a la red neuronal. Para lograr este\n",
    "> objetivo, se utilizaron los valores del cuadro compartido (el segundo) de manera tal que, la lista de datos entregada fuera una matriz de 3\n",
    "> columnas y 10 filas que, corresponderian a la cantidad de variables utilizadas y datos entregados respectivamente. En base a esto\n",
    "> los datos adquiririan la siguiente forma:\n",
    "> \\begin{align*} D &= \\begin{pmatrix} 9 & 7 & 0 \\\\ 2 & 5 & 1 \\\\ 3.2 & 4.94 & 1 \\\\ 9.1 & 7.46 & 0 \\\\ 1.6 & 4.83 & 1 \\\\ 8.4 & 7.46 & 0 \\\\ 8.0 & 7.28 & 0 \\\\ 3.1 & 4.58 & 1 \\\\ 6.3 & 9.14 & 0 \\\\ 3.4 & 5.36 & 1 \\end{pmatrix} \\, x_{0} = \\begin{pmatrix} 8 \\\\ 7\\end{pmatrix} \\end{align*}\n",
    "> Si bien, agregar la forma teorica de la matriz y el vector de inspiracion no fue solicitado, este se agrego con el fin de mostrar la\n",
    "> interpretacion de estos valores, los cuales se alteran utilizando operaciones matriciales en su mayoria. Finalmente, el codigo utilizado quedaria\n",
    "> de la siguiente manera\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "# ======================================== Tarea 2, Parte 2.b ============================================\n",
    "####################################### Gradiente Conjugado ##############################################\n",
    "# Desarrollo final\n",
    "#   I. Ejecutar el gradiente para obtener el Phi = (wk1, wk2, bk2)\n",
    "#   II. Llamando \"phi = gradiente conjugado\", ejercutamos la\n",
    "#       realizacion en (8, 7) y phi\n",
    "# I.\n",
    "phiconjugado = gradienteConjugado(1000, w1, w2, b, l, D)              # Aplicacion del gradiente conjugado\n",
    "print(phiconjugado)                                                   # Mostrar resultados\n",
    "# II.\n",
    "redrealizada = realizacion(phiconjugado, X0, 0, 0)                    # Obtencion de red neuronal\n",
    "print(redrealizada)                                                   # Mostrar resultados\n",
    "####################################### Gradiente Conjugado ##############################################\n",
    "# ======================================== Tarea 2, Parte 2.b ============================================"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> ## Palabras Finales:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> vv"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
